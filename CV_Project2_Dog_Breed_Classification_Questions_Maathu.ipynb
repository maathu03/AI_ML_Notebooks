{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kIWaR5ZpKlJ"
   },
   "source": [
    "## Dog Breed Classification\n",
    "\n",
    "In this project we will use traditional CNN, CNN with data augmentation and finally transfer Learning by VGG16 model with weights pre-trained on Imagenet to solve the dog breed classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F7MDmaAw2xGO"
   },
   "source": [
    "### Load Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1019,
     "status": "ok",
     "timestamp": 1554651614879,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "BZWpQv1OwqYK",
    "outputId": "b799ad7f-291b-410e-c9fa-75450223e458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Importing data from Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVhB9OopxFbX"
   },
   "outputs": [],
   "source": [
    "# Importing required packages\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing keras package\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1q2zzIaUprk_"
   },
   "source": [
    "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tp6FvAToxUFs"
   },
   "outputs": [],
   "source": [
    "# Setting the project path\n",
    "project_path = '/content/drive/My Drive/AIML_Project/Dog_breed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rydR_j8lqUei"
   },
   "source": [
    "Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3350WZM4w4EL"
   },
   "outputs": [],
   "source": [
    "# Extracting the training data set\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'train.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NHq1iBCfFjE"
   },
   "source": [
    "Repeat the same step for test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fxzynvB2YCb"
   },
   "outputs": [],
   "source": [
    "# Extracting the test data set\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'test.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jnUMhQrDfJmz"
   },
   "source": [
    "Repeat the same step for sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PyTxE8q2jLf"
   },
   "outputs": [],
   "source": [
    "# Extracting the sample submission.csv file\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'sample_submission.csv.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2G9RIxB-fOLT"
   },
   "source": [
    "Repeat the same step for labels.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rXtnEoEixbgi"
   },
   "outputs": [],
   "source": [
    "# Extracting the labels.csv file\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(project_path+'labels.csv.zip', 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJc1lVrW_jmL"
   },
   "source": [
    "After this process, we will have 4 files - Train folder, test folder and labels.csv and sample_submission.csv as part of your google drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYmJKmDqqpng"
   },
   "source": [
    "### Read labels.csv file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmlJ2VMY96IZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPvb1RSc96If"
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QP8YAzQvqyK-"
   },
   "source": [
    "### Print the count of each category of Dogs given in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1611,
     "status": "ok",
     "timestamp": 1554651640337,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "3L2naXlr96Im",
    "outputId": "8a161633-fcee-4f6d-bc6d-63cc6e62c4e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scottish_deerhound                126\n",
       "maltese_dog                       117\n",
       "afghan_hound                      116\n",
       "entlebucher                       115\n",
       "bernese_mountain_dog              114\n",
       "shih-tzu                          112\n",
       "pomeranian                        111\n",
       "great_pyrenees                    111\n",
       "basenji                           110\n",
       "samoyed                           109\n",
       "airedale                          107\n",
       "tibetan_terrier                   107\n",
       "leonberg                          106\n",
       "cairn                             106\n",
       "japanese_spaniel                  105\n",
       "beagle                            105\n",
       "blenheim_spaniel                  102\n",
       "australian_terrier                102\n",
       "miniature_pinscher                102\n",
       "irish_wolfhound                   101\n",
       "saluki                             99\n",
       "lakeland_terrier                   99\n",
       "papillon                           96\n",
       "whippet                            95\n",
       "norwegian_elkhound                 95\n",
       "siberian_husky                     95\n",
       "pug                                94\n",
       "chow                               93\n",
       "pembroke                           92\n",
       "italian_greyhound                  92\n",
       "                                 ... \n",
       "bull_mastiff                       75\n",
       "english_springer                   75\n",
       "pekinese                           75\n",
       "borzoi                             75\n",
       "great_dane                         75\n",
       "cocker_spaniel                     74\n",
       "doberman                           74\n",
       "american_staffordshire_terrier     74\n",
       "malinois                           73\n",
       "brittany_spaniel                   73\n",
       "flat-coated_retriever              72\n",
       "redbone                            72\n",
       "border_collie                      72\n",
       "curly-coated_retriever             72\n",
       "standard_schnauzer                 72\n",
       "soft-coated_wheaten_terrier        71\n",
       "chihuahua                          71\n",
       "kuvasz                             71\n",
       "french_bulldog                     70\n",
       "vizsla                             70\n",
       "walker_hound                       69\n",
       "giant_schnauzer                    69\n",
       "german_shepherd                    69\n",
       "otterhound                         69\n",
       "tibetan_mastiff                    69\n",
       "golden_retriever                   67\n",
       "komondor                           67\n",
       "brabancon_griffon                  67\n",
       "briard                             66\n",
       "eskimo_dog                         66\n",
       "Name: breed, Length: 120, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df['breed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WI94_Qcc0D4M"
   },
   "source": [
    "### Get one-hot encodings of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q48iAcY196I3"
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#le = LabelEncoder()\n",
    "#labels_df['breed'] = le.fit_transform(labels_df['breed'])\n",
    "y = pd.get_dummies(labels_df['breed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1554651644536,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "9nlWmRNM96I8",
    "outputId": "84875665-a806-40e6-8bf4-f540d9b20520"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWaJ9naXfoiU"
   },
   "source": [
    "## Preparing training dataset\n",
    "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
    "2. Create 2 variables <br> \n",
    "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
    "     b.  y_train - Corresponding label of the dog <br>\n",
    "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
    "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1554651646871,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "aC2f9ecR0XGR",
    "outputId": "f299747a-f9e2-43e2-fd97-688d2f0d0e9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.config',\n",
       " 'sample_submission.csv',\n",
       " 'labels.csv',\n",
       " 'test',\n",
       " 'drive',\n",
       " 'train',\n",
       " 'sample_data']"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkkZEpOe0ipk"
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "import cv2\n",
    "for index,row in labels_df.iterrows():\n",
    "  try:   \n",
    "      temp = cv2.imread('./train/' + row['id'] + '.jpg')\n",
    "      temp = cv2.resize(temp,(128,128))\n",
    "      x_train.append(temp)\n",
    "      #y_train.append(row['breed'])\n",
    "  except Exception as e:\n",
    "      print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29218,
     "status": "ok",
     "timestamp": 1554651676516,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "tYrajJGl3rV7",
    "outputId": "8136e173-c34c-4d9e-f921-91d53eab78e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ioWDEgElBOs"
   },
   "source": [
    "Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARn76j3U1CDa"
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rvt-wkxD3h66"
   },
   "outputs": [],
   "source": [
    "#Normalize training set\n",
    "x_train = x_train/255;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27484,
     "status": "ok",
     "timestamp": 1554651680376,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "vpcauQD3JPUJ",
    "outputId": "a63e2fc5-810a-471a-ec40-4418a0ea3ac6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10222, 128, 128, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdCXuAE11gZL"
   },
   "source": [
    "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpWx-pgV96Jv"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkL-N1jDsU8m"
   },
   "source": [
    "### Loading the test data\n",
    "Read the id column from the samples_submission.csv and store it in test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnpXdpd9b3E7"
   },
   "outputs": [],
   "source": [
    "test_img = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22866,
     "status": "ok",
     "timestamp": 1554650273687,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "yDFuriLMMG5T",
    "outputId": "f9fb3096-6198-46d6-a1fe-f31f4870acf1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  affenpinscher  afghan_hound  \\\n",
       "0  000621fb3cbb32d8935728e48679680e       0.008333      0.008333   \n",
       "1  00102ee9d8eb90812350685311fe5890       0.008333      0.008333   \n",
       "2  0012a730dfa437f5f3613fb75efcd4ce       0.008333      0.008333   \n",
       "3  001510bc8570bbeee98c8d80c8a95ec1       0.008333      0.008333   \n",
       "4  001a5f3114548acdefa3d4da05474c2e       0.008333      0.008333   \n",
       "\n",
       "   african_hunting_dog  airedale  american_staffordshire_terrier  appenzeller  \\\n",
       "0             0.008333  0.008333                        0.008333     0.008333   \n",
       "1             0.008333  0.008333                        0.008333     0.008333   \n",
       "2             0.008333  0.008333                        0.008333     0.008333   \n",
       "3             0.008333  0.008333                        0.008333     0.008333   \n",
       "4             0.008333  0.008333                        0.008333     0.008333   \n",
       "\n",
       "   australian_terrier   basenji    basset        ...          toy_poodle  \\\n",
       "0            0.008333  0.008333  0.008333        ...            0.008333   \n",
       "1            0.008333  0.008333  0.008333        ...            0.008333   \n",
       "2            0.008333  0.008333  0.008333        ...            0.008333   \n",
       "3            0.008333  0.008333  0.008333        ...            0.008333   \n",
       "4            0.008333  0.008333  0.008333        ...            0.008333   \n",
       "\n",
       "   toy_terrier    vizsla  walker_hound  weimaraner  welsh_springer_spaniel  \\\n",
       "0     0.008333  0.008333      0.008333    0.008333                0.008333   \n",
       "1     0.008333  0.008333      0.008333    0.008333                0.008333   \n",
       "2     0.008333  0.008333      0.008333    0.008333                0.008333   \n",
       "3     0.008333  0.008333      0.008333    0.008333                0.008333   \n",
       "4     0.008333  0.008333      0.008333    0.008333                0.008333   \n",
       "\n",
       "   west_highland_white_terrier   whippet  wire-haired_fox_terrier  \\\n",
       "0                     0.008333  0.008333                 0.008333   \n",
       "1                     0.008333  0.008333                 0.008333   \n",
       "2                     0.008333  0.008333                 0.008333   \n",
       "3                     0.008333  0.008333                 0.008333   \n",
       "4                     0.008333  0.008333                 0.008333   \n",
       "\n",
       "   yorkshire_terrier  \n",
       "0           0.008333  \n",
       "1           0.008333  \n",
       "2           0.008333  \n",
       "3           0.008333  \n",
       "4           0.008333  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEJqZIMbm0Jo"
   },
   "source": [
    "Run the below code to load the test image files in x_test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zf7n4WG-b3Hv"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "x_test_feature = []\n",
    "i = 0 # initialisation\n",
    "for index,row in test_img.iterrows():\n",
    "    img = cv2.imread('./test/' + row['id'] +'.jpg')\n",
    "    img_resize = cv2.resize(img, (128, 128)) \n",
    "    x_test_feature.append(img_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9My6qSyDnE-_"
   },
   "source": [
    "Normalize the test data and convert it into 4 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93n-IntMnJGI"
   },
   "outputs": [],
   "source": [
    "x_test_feature = np.array(x_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25938,
     "status": "ok",
     "timestamp": 1554649211520,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "iZYYOUhPsK7Y",
    "outputId": "2942e662-ac01-4586-9521-605a92e6a6dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10357, 128, 128, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VmvdHCp8sLW7"
   },
   "outputs": [],
   "source": [
    "x_test_feature = x_test_feature/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKezNJVMsocP"
   },
   "source": [
    "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
    "\n",
    "1. Add a Dense layer with 256 neurons with `relu` activation\n",
    "\n",
    "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2493,
     "status": "ok",
     "timestamp": 1554651699529,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "D2jxTY2S96J4",
    "outputId": "608aeaeb-2577-425c-89dc-716d9ec08a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "#Normalizing the data\n",
    "model.add(BatchNormalization(input_shape=(128, 128, 3)))\n",
    "\n",
    "# 1st Conv Layer\n",
    "model.add(Convolution2D(256, (5, 5), input_shape=(128, 128, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# 2nd Conv Layer\n",
    "model.add(Convolution2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_BAvCzo96J6"
   },
   "outputs": [],
   "source": [
    "# Prediction Layer\n",
    "model.add(Dense(120))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ui8EXw6_oqpR"
   },
   "source": [
    "### Use batch_size = 128 and epochs = 10 and execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IriIc37NozbK"
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 437993,
     "status": "ok",
     "timestamp": 1554650731013,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "0PR9j5_Xozmd",
    "outputId": "523e3d4b-2673-46eb-cd7a-bd8e9a5f1ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8177 samples, validate on 2045 samples\n",
      "Epoch 1/10\n",
      "8177/8177 [==============================] - 54s 7ms/step - loss: 4.8319 - acc: 0.0086 - val_loss: 4.7864 - val_acc: 0.0098\n",
      "Epoch 2/10\n",
      "8177/8177 [==============================] - 42s 5ms/step - loss: 4.7855 - acc: 0.0110 - val_loss: 4.7856 - val_acc: 0.0098\n",
      "Epoch 3/10\n",
      "8177/8177 [==============================] - 43s 5ms/step - loss: 4.7841 - acc: 0.0119 - val_loss: 4.7848 - val_acc: 0.0098\n",
      "Epoch 4/10\n",
      "8177/8177 [==============================] - 43s 5ms/step - loss: 4.7828 - acc: 0.0119 - val_loss: 4.7842 - val_acc: 0.0098\n",
      "Epoch 5/10\n",
      "8177/8177 [==============================] - 42s 5ms/step - loss: 4.7816 - acc: 0.0106 - val_loss: 4.7837 - val_acc: 0.0098\n",
      "Epoch 6/10\n",
      "8177/8177 [==============================] - 42s 5ms/step - loss: 4.7806 - acc: 0.0119 - val_loss: 4.7832 - val_acc: 0.0098\n",
      "Epoch 7/10\n",
      "8177/8177 [==============================] - 43s 5ms/step - loss: 4.7796 - acc: 0.0119 - val_loss: 4.7829 - val_acc: 0.0098\n",
      "Epoch 8/10\n",
      "8177/8177 [==============================] - 43s 5ms/step - loss: 4.7787 - acc: 0.0102 - val_loss: 4.7827 - val_acc: 0.0098\n",
      "Epoch 9/10\n",
      "8177/8177 [==============================] - 43s 5ms/step - loss: 4.7780 - acc: 0.0119 - val_loss: 4.7827 - val_acc: 0.0098\n",
      "Epoch 10/10\n",
      "8177/8177 [==============================] - 43s 5ms/step - loss: 4.7773 - acc: 0.0119 - val_loss: 4.7827 - val_acc: 0.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc903ce518>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, Y_train, batch_size=128, nb_epoch=10, \n",
    "        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17625,
     "status": "ok",
     "timestamp": 1554650760198,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "AzeQSqHa192X",
    "outputId": "1eb2989a-2c55-471c-c07e-8c1ce48e5919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8177/8177 [==============================] - 17s 2ms/step\n",
      "Training accuracy:  0.01186254127430598\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "score = model.evaluate(X_train, Y_train)\n",
    "print('Training accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21457,
     "status": "ok",
     "timestamp": 1554650764493,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "cV5N0J9f1_Al",
    "outputId": "17e351e0-1fa3-4a2b-fdb8-862d26c37de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2045/2045 [==============================] - 4s 2ms/step\n",
      "Training accuracy:  0.009779951096601184\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Training accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z8hWaKmjoz69"
   },
   "source": [
    "#The model accuracy is very poor !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agJKkc6xtKiq"
   },
   "source": [
    "### Use Data Augmentation in the above model to see if the accuracy improves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31Mn8qnZb3Ru"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  \n",
    "    samplewise_center=False, \n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=50,  \n",
    "    width_shift_range=0.1,  \n",
    "    height_shift_range=0.1, \n",
    "    horizontal_flip=False,  \n",
    "    vertical_flip=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDLQVFDP96KI"
   },
   "outputs": [],
   "source": [
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqTlW0qHb3Xb"
   },
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  \n",
    "    samplewise_center=False, \n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=50,  \n",
    "    width_shift_range=0.1,  \n",
    "    height_shift_range=0.1, \n",
    "    horizontal_flip=False,  \n",
    "    vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYW7wev6KQiD"
   },
   "outputs": [],
   "source": [
    "val_datagen.fit(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sssbaTfxlkk"
   },
   "source": [
    "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
    "\n",
    "You need to use train_datagen.flow() and val_datagen.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sehaRgT-96KQ"
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(X_train, Y_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iyi7OvorMjzL"
   },
   "outputs": [],
   "source": [
    "val_generator = val_datagen.flow(X_test, Y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVFQJZw3x4-C"
   },
   "source": [
    "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 554187,
     "status": "ok",
     "timestamp": 1554652429958,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "J1K2MqHbuPUa",
    "outputId": "fcbcbf5b-4191-4feb-97e8-065d6a8bae7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "256/255 [==============================] - 61s 240ms/step - loss: 4.7967 - acc: 0.0104 - val_loss: 4.7857 - val_acc: 0.0098\n",
      "Epoch 2/10\n",
      "256/255 [==============================] - 55s 214ms/step - loss: 4.7840 - acc: 0.0112 - val_loss: 4.7843 - val_acc: 0.0098\n",
      "Epoch 3/10\n",
      "256/255 [==============================] - 55s 213ms/step - loss: 4.7816 - acc: 0.0118 - val_loss: 4.7833 - val_acc: 0.0098\n",
      "Epoch 4/10\n",
      "256/255 [==============================] - 55s 214ms/step - loss: 4.7797 - acc: 0.0101 - val_loss: 4.7828 - val_acc: 0.0098\n",
      "Epoch 5/10\n",
      "256/255 [==============================] - 54s 213ms/step - loss: 4.7784 - acc: 0.0111 - val_loss: 4.7828 - val_acc: 0.0098\n",
      "Epoch 6/10\n",
      "256/255 [==============================] - 55s 213ms/step - loss: 4.7776 - acc: 0.0118 - val_loss: 4.7831 - val_acc: 0.0098\n",
      "Epoch 7/10\n",
      "256/255 [==============================] - 55s 213ms/step - loss: 4.7771 - acc: 0.0111 - val_loss: 4.7834 - val_acc: 0.0098\n",
      "Epoch 8/10\n",
      "256/255 [==============================] - 55s 214ms/step - loss: 4.7769 - acc: 0.0118 - val_loss: 4.7835 - val_acc: 0.0098\n",
      "Epoch 9/10\n",
      "256/255 [==============================] - 55s 214ms/step - loss: 4.7766 - acc: 0.0118 - val_loss: 4.7837 - val_acc: 0.0098\n",
      "Epoch 10/10\n",
      "256/255 [==============================] - 54s 212ms/step - loss: 4.7766 - acc: 0.0118 - val_loss: 4.7840 - val_acc: 0.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc7b7afda0>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(X_train) / 32,\n",
    "        epochs=10,\n",
    "        validation_data=val_generator,validation_steps = len(X_test) / 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17862,
     "status": "ok",
     "timestamp": 1554652505124,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "L3J1T9b7I99a",
    "outputId": "e65d94f8-924f-4521-dfa9-c0c1bb5c227f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8177/8177 [==============================] - 17s 2ms/step\n",
      "Training accuracy:  0.01186254127430598\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "score = model.evaluate(X_train, Y_train)\n",
    "print('Training accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4938,
     "status": "ok",
     "timestamp": 1554652537168,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "LkvOhCG7I-LR",
    "outputId": "85bd116a-10a8-462f-f111-4a973f07aa2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2045/2045 [==============================] - 4s 2ms/step\n",
      "Test accuracy:  0.009779951096601184\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2zmLztqo5DY"
   },
   "source": [
    "# Model accuracy is still poor!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSTATrhsAo7L"
   },
   "source": [
    "### Lets use Transfer Learning\n",
    "\n",
    "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zy5JdbW6pIvD"
   },
   "source": [
    "Use the below code to load VGG16 weights trained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrqs0zg7ApNw"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "# Instantiate the model with the pre-trained weights (no top)\n",
    "base_model= VGG16(weights=(project_path+'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'),\n",
    "                 include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EItOlRBGpV_A"
   },
   "source": [
    "Print the summary of the base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 871,
     "status": "ok",
     "timestamp": 1554653419314,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "lQsEBgnlpHjH",
    "outputId": "b14a3e70-1708-4d78-f34d-b12818af5575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHpeOyW0qauW"
   },
   "source": [
    "### Add the following classification layers to the imported VGG Model <br>\n",
    "1. Flatten Layer\n",
    "2. Dense layer with 1024 neurons with activation as Relu\n",
    "3. Dense layer with 256 neurons with activation as Relu\n",
    "4. Dense layer with 120 neurons with activation as Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BpT4MLkqoaO"
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "predictions = Dense(120, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeQem0pHITIj"
   },
   "source": [
    "### Make all the layers in the base_model (VGG16) to be non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7w9CSPvIRnX"
   },
   "outputs": [],
   "source": [
    "# Freeze the layers which you don't want to train. In this we are freezing the first 5 layers.\n",
    "for layer in base_model.layers[:5]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kj-BwqgfIkdv"
   },
   "source": [
    "### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YD5fAgVQIpKZ"
   },
   "source": [
    "Try to get training and validation accuracy to be more than 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 509,
     "status": "error",
     "timestamp": 1554654677050,
     "user": {
      "displayName": "pradeep kumar",
      "photoUrl": "https://lh3.googleusercontent.com/-FmPNlSUV-aM/AAAAAAAAAAI/AAAAAAAAL9c/XCpjOS8oDKo/s64/photo.jpg",
      "userId": "14820859138256956195"
     },
     "user_tz": 420
    },
    "id": "SZk2SWvjIoRP",
    "outputId": "f8625913-6273-4e35-e3e6-a5bbf24d6d7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-8f6636786a2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 342\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   3292\u001b[0m         \u001b[0;31m# manual computation of crossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3293\u001b[0m         \u001b[0m_epsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3294\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_epsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0m_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3295\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/clip_ops.py\u001b[0m in \u001b[0;36mclip_by_value\u001b[0;34m(t, clip_value_min, clip_value_max, name)\u001b[0m\n\u001b[1;32m     66\u001b[0m   \"\"\"\n\u001b[1;32m     67\u001b[0m   with ops.name_scope(name, \"clip_by_value\",\n\u001b[0;32m---> 68\u001b[0;31m                       [t, clip_value_min, clip_value_max]) as name:\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6081\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6082\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6083\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6084\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   5711\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5712\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5713\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5714\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5715\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   5647\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5648\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[0;32m-> 5649\u001b[0;31m                                                                 original_item))\n\u001b[0m\u001b[1;32m   5650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"loss/dense_5_loss/Const:0\", shape=(), dtype=float32) must be from the same graph as Tensor(\"truediv:0\", shape=(?, 120), dtype=float32)."
     ]
    }
   ],
   "source": [
    "# creating the final model \n",
    "model_final = Model(input = base_model.input, output = predictions)\n",
    "\n",
    "sgd = SGD(lr=0.001)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = sgd, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VtLhk7RBPtfr"
   },
   "outputs": [],
   "source": [
    "# Save the model \n",
    "checkpoint = ModelCheckpoint(\"vgg16_best.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "epochs=20\n",
    "# Train the model \n",
    "model_final.fit(X_train, Y_train, epochs = epochs, validation_data=(X_test, Y_test), callbacks = [checkpoint, early])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CV_Project2_Dog_Breed_Classification_Questions.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
